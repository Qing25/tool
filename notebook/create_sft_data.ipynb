{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from qdls.data import load_json, save_json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyse the dependent relations \n",
    "\n",
    "FinalAll() 后续会是哪个函数名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qing/raid/paperwork/kgtool/data/kqa/full/train.json loaded with 94376 samples!\n",
      "/home/qing/raid/paperwork/kgtool/data/kqa/full/val.json loaded with 11797 samples!\n"
     ]
    }
   ],
   "source": [
    "train = load_json(\"/home/qing/raid/paperwork/kgtool/data/kqa/full/train.json\")\n",
    "val = load_json(\"/home/qing/raid/paperwork/kgtool/data/kqa/full/val.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Functions:\n",
      "Find: 128457\n",
      "FilterConcept: 59963\n",
      "Relate: 50257\n",
      "FindAll: 30266\n",
      "FilterStr: 25305\n",
      "And: 25302\n",
      "QueryAttr: 22265\n",
      "QueryRelation: 13876\n",
      "SelectBetween: 13247\n",
      "What: 11174\n",
      "\n",
      "total distinct function sequences: 830\n",
      "\n",
      "Most Common Sequences:\n",
      "Find → Find → QueryRelation: 7152\n",
      "Find → Find → SelectBetween: 5438\n",
      "Find → Find → QueryRelationQualifier: 4013\n",
      "FindAll → FilterStr → FilterConcept → QueryAttr: 3257\n",
      "Find → Relate → Find → And → Find → QueryRelation: 3002\n",
      "Find → QueryAttr: 2873\n",
      "FindAll → FilterStr → FilterConcept → QueryAttrQualifier: 2727\n",
      "FindAll → FilterStr → FilterConcept → What: 2322\n",
      "Find → QueryAttrQualifier: 2280\n",
      "FindAll → FilterNum → FilterConcept → SelectAmong: 2197\n",
      "\n",
      "Common Bigrams (Potential Dependencies):\n",
      "Find → Relate: 39214\n",
      "Relate → FilterConcept: 26564\n",
      "Find → Find: 21537\n",
      "FindAll → FilterStr: 20797\n",
      "Relate → Find: 20560\n",
      "Find → And: 20560\n",
      "FilterStr → FilterConcept: 19524\n",
      "FilterConcept → QueryAttr: 13844\n",
      "Find → QueryRelation: 11720\n",
      "And → Find: 8822\n",
      "\n",
      "Sequence Length Distribution:\n",
      "2 steps: 5153 examples\n",
      "3 steps: 20693 examples\n",
      "4 steps: 26851 examples\n",
      "5 steps: 11446 examples\n",
      "6 steps: 14773 examples\n",
      "7 steps: 4415 examples\n",
      "8 steps: 7268 examples\n",
      "9 steps: 2582 examples\n",
      "10 steps: 65 examples\n",
      "11 steps: 957 examples\n",
      "12 steps: 119 examples\n",
      "13 steps: 2 examples\n",
      "14 steps: 49 examples\n",
      "15 steps: 3 examples\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from typing import List, Dict, Tuple, Set\n",
    "\n",
    "# ... existing imports ...\n",
    "\n",
    "def analyze_function_patterns(train_data: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze function call patterns in training data.\n",
    "    \n",
    "    Args:\n",
    "        train_data: List of training examples containing programs\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with analysis results containing:\n",
    "        - function_freq: Frequency distribution of individual functions\n",
    "        - seq_freq: Frequency of unique function sequences\n",
    "        - common_bigrams: Most common function pairs\n",
    "        - seq_length_dist: Sequence length distribution\n",
    "        \n",
    "    Example:\n",
    "        >>> train_data = load_json(\"train.json\")\n",
    "        >>> analysis = analyze_function_patterns(train_data)\n",
    "    \"\"\"\n",
    "    function_freq = Counter()\n",
    "    seq_counter = Counter()\n",
    "    seq_lengths = Counter()\n",
    "    bigram_counter = Counter()\n",
    "\n",
    "    for s in train_data:\n",
    "        program = s[\"program\"]\n",
    "        functions = [f['function'] for f in program]\n",
    "        \n",
    "        # Update frequency counts\n",
    "        function_freq.update(functions)\n",
    "        seq_counter[tuple(functions)] += 1  # Store sequence as tuple for hashability\n",
    "        seq_lengths[len(functions)] += 1\n",
    "        \n",
    "        # Track bigrams for dependency analysis\n",
    "        bigram_counter.update(zip(functions, functions[1:]))\n",
    "\n",
    "    return {\n",
    "        'function_freq': function_freq.most_common(),\n",
    "        'seq_freq': seq_counter.most_common(10),\n",
    "        'common_bigrams': bigram_counter.most_common(10),\n",
    "        'seq_length_dist': sorted(seq_lengths.items())\n",
    "    }, function_freq, seq_counter, bigram_counter\n",
    "\n",
    "# Usage example\n",
    "\n",
    "analysis,function_freq, seq_counter, bigram_counter = analyze_function_patterns(train)\n",
    "\n",
    "# Generate report\n",
    "print(\"Top 10 Functions:\")\n",
    "for func, count in analysis['function_freq'][:10]:\n",
    "    print(f\"{func}: {count}\")\n",
    "\n",
    "print(f\"\\ntotal distinct function sequences: {len(seq_counter)}\")\n",
    "\n",
    "print(\"\\nMost Common Sequences:\")\n",
    "for seq, count in analysis['seq_freq']:\n",
    "    print(f\"{' → '.join(seq)}: {count}\")\n",
    "\n",
    "print(\"\\nCommon Bigrams (Potential Dependencies):\")\n",
    "for (f1, f2), count in analysis['common_bigrams']:\n",
    "    print(f\"{f1} → {f2}: {count}\")\n",
    "\n",
    "print(\"\\nSequence Length Distribution:\")\n",
    "for length, count in analysis['seq_length_dist']:\n",
    "    print(f\"{length} steps: {count} examples\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('FindAll', 'FilterStr'), ('FilterStr', 'FilterConcept'), ('FilterConcept', 'FindAll'), ('FilterConcept', 'And'), ('And', 'What'), ('FilterConcept', 'QueryAttr'), ('QueryAttr', 'VerifyStr'), ('FindAll', 'FilterNum'), ('FilterNum', 'FilterConcept'), ('FilterConcept', 'SelectAmong'), ('Find', 'Relate'), ('Relate', 'Find'), ('Find', 'And'), ('And', 'Find'), ('And', 'QueryRelation'), ('Relate', 'FilterConcept'), ('FilterConcept', 'QueryAttrQualifier'), ('Find', 'SelectBetween'), ('FilterConcept', 'Relate'), ('FilterConcept', 'Count'), ('Find', 'Find'), ('Find', 'QueryRelationQualifier'), ('And', 'Relate'), ('Find', 'FilterNum'), ('FilterNum', 'Find'), ('QueryAttr', 'VerifyDate'), ('Find', 'QueryRelation'), ('Find', 'QueryAttr'), ('QueryAttr', 'VerifyYear'), ('FilterConcept', 'Or'), ('Or', 'Count'), ('And', 'QueryRelationQualifier'), ('FilterStr', 'QFilterStr'), ('QFilterStr', 'FilterConcept'), ('Find', 'QueryAttrQualifier'), ('FilterConcept', 'What'), ('And', 'SelectBetween'), ('Find', 'FilterStr'), ('FilterStr', 'QueryRelationQualifier'), ('FilterStr', 'Relate'), ('FindAll', 'FilterYear'), ('FilterYear', 'FilterConcept'), ('FilterConcept', 'Find'), ('FilterStr', 'SelectBetween'), ('And', 'Count'), ('FilterStr', 'QFilterNum'), ('QFilterNum', 'FilterConcept'), ('FilterNum', 'Relate'), ('QueryAttr', 'VerifyNum'), ('FindAll', 'FilterDate'), ('FilterDate', 'FilterConcept'), ('And', 'QueryAttr'), ('FilterStr', 'Find'), ('FilterStr', 'QueryRelation'), ('Find', 'FilterYear'), ('FilterYear', 'Find'), ('FilterNum', 'QueryAttr'), ('Relate', 'QFilterStr'), ('FilterNum', 'QueryRelation'), ('FilterNum', 'SelectBetween'), ('FilterNum', 'QueryAttrUnderCondition'), ('QueryAttrUnderCondition', 'VerifyYear'), ('And', 'QueryAttrQualifier'), ('Find', 'FilterDate'), ('FilterDate', 'SelectBetween'), ('FilterDate', 'Find'), ('Find', 'QueryAttrUnderCondition'), ('QueryAttrUnderCondition', 'VerifyNum'), ('FilterConcept', 'QueryAttrUnderCondition'), ('FilterDate', 'QueryAttr'), ('Relate', 'QFilterDate'), ('QFilterDate', 'FilterConcept'), ('Relate', 'QFilterNum'), ('FilterDate', 'QueryAttrQualifier'), ('FindAll', 'FilterConcept'), ('FilterNum', 'QFilterYear'), ('QFilterYear', 'FilterConcept'), ('Relate', 'QFilterYear'), ('QueryAttrUnderCondition', 'VerifyDate'), ('FilterDate', 'Relate'), ('FilterYear', 'QueryRelation'), ('FilterNum', 'QueryAttrQualifier'), ('FilterNum', 'QFilterStr'), ('FilterYear', 'QueryAttr'), ('FilterDate', 'QueryRelation'), ('FilterStr', 'QFilterYear'), ('QueryAttrUnderCondition', 'VerifyStr'), ('FilterYear', 'QFilterStr'), ('FilterStr', 'QueryAttrQualifier'), ('FilterNum', 'QueryRelationQualifier'), ('And', 'QueryAttrUnderCondition'), ('FilterStr', 'QueryAttr'), ('FilterYear', 'Relate'), ('FilterYear', 'SelectBetween'), ('FilterStr', 'QFilterDate'), ('FilterNum', 'QFilterDate'), ('FilterDate', 'QFilterStr'), ('FilterStr', 'QueryAttrUnderCondition'), ('FilterYear', 'QueryRelationQualifier'), ('FilterYear', 'QueryAttrQualifier'), ('FilterNum', 'QFilterNum'), ('FilterDate', 'QueryRelationQualifier'), ('FilterYear', 'QueryAttrUnderCondition'), ('FilterDate', 'QueryAttrUnderCondition'), ('FilterYear', 'QFilterYear')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_counter.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将 function name 的转移关系建模成规则\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Rules:\n",
      "After FindAll, allowed: ['FilterStr', 'FilterNum', 'FilterYear', 'FilterDate', 'FilterConcept']\n",
      "After FilterStr, allowed: ['FilterConcept', 'QFilterStr', 'QueryRelationQualifier', 'Relate', 'SelectBetween', 'QFilterNum', 'Find', 'QueryRelation', 'QFilterYear', 'QueryAttrQualifier', 'QueryAttr', 'QFilterDate', 'QueryAttrUnderCondition']\n",
      "After FilterConcept, allowed: ['FindAll', 'And', 'QueryAttr', 'SelectAmong', 'QueryAttrQualifier', 'Relate', 'Count', 'Or', 'What', 'Find', 'QueryAttrUnderCondition']\n",
      "After And, allowed: ['What', 'Find', 'QueryRelation', 'Relate', 'QueryRelationQualifier', 'SelectBetween', 'Count', 'QueryAttr', 'QueryAttrQualifier', 'QueryAttrUnderCondition']\n",
      "After QueryAttr, allowed: ['VerifyStr', 'VerifyDate', 'VerifyYear', 'VerifyNum']\n",
      "After FilterNum, allowed: ['FilterConcept', 'Find', 'Relate', 'QueryAttr', 'QueryRelation', 'SelectBetween', 'QueryAttrUnderCondition', 'QFilterYear', 'QueryAttrQualifier', 'QFilterStr', 'QueryRelationQualifier', 'QFilterDate', 'QFilterNum']\n",
      "After Find, allowed: ['Relate', 'And', 'SelectBetween', 'Find', 'QueryRelationQualifier', 'FilterNum', 'QueryRelation', 'QueryAttr', 'QueryAttrQualifier', 'FilterStr', 'FilterYear', 'FilterDate', 'QueryAttrUnderCondition']\n",
      "After Relate, allowed: ['Find', 'FilterConcept', 'QFilterStr', 'QFilterDate', 'QFilterNum', 'QFilterYear']\n",
      "After Or, allowed: ['Count']\n",
      "After QFilterStr, allowed: ['FilterConcept']\n",
      "After FilterYear, allowed: ['FilterConcept', 'Find', 'QueryRelation', 'QueryAttr', 'QFilterStr', 'Relate', 'SelectBetween', 'QueryRelationQualifier', 'QueryAttrQualifier', 'QueryAttrUnderCondition', 'QFilterYear']\n",
      "After QFilterNum, allowed: ['FilterConcept']\n",
      "After FilterDate, allowed: ['FilterConcept', 'SelectBetween', 'Find', 'QueryAttr', 'QueryAttrQualifier', 'Relate', 'QueryRelation', 'QFilterStr', 'QueryRelationQualifier', 'QueryAttrUnderCondition']\n",
      "After QueryAttrUnderCondition, allowed: ['VerifyYear', 'VerifyNum', 'VerifyDate', 'VerifyStr']\n",
      "After QFilterDate, allowed: ['FilterConcept']\n",
      "After QFilterYear, allowed: ['FilterConcept']\n",
      "\n",
      "Likely transitions from FindAll:\n",
      "- FilterStr: 68.71% probability\n",
      "- FilterNum: 16.32% probability\n",
      "- FilterYear: 11.82% probability\n",
      "\n",
      "Likely transitions from FilterStr:\n",
      "- FilterConcept: 77.15% probability\n",
      "- Find: 6.39% probability\n",
      "- Relate: 4.21% probability\n",
      "\n",
      "Likely transitions from FilterConcept:\n",
      "- QueryAttr: 23.09% probability\n",
      "- What: 13.20% probability\n",
      "- QueryAttrQualifier: 10.63% probability\n",
      "\n",
      "Likely transitions from And:\n",
      "- Find: 34.87% probability\n",
      "- Relate: 16.63% probability\n",
      "- What: 12.88% probability\n",
      "\n",
      "Likely transitions from What:\n",
      "\n",
      "Likely transitions from QueryAttr:\n",
      "- VerifyStr: 51.34% probability\n",
      "- VerifyYear: 32.64% probability\n",
      "- VerifyNum: 14.48% probability\n",
      "\n",
      "Likely transitions from VerifyStr:\n",
      "\n",
      "Likely transitions from FilterNum:\n",
      "- FilterConcept: 49.64% probability\n",
      "- Find: 17.75% probability\n",
      "- SelectBetween: 10.27% probability\n",
      "\n",
      "Likely transitions from SelectAmong:\n",
      "\n",
      "Likely transitions from Find:\n",
      "- Relate: 30.53% probability\n",
      "- Find: 16.77% probability\n",
      "- And: 16.01% probability\n",
      "\n",
      "Likely transitions from Relate:\n",
      "- FilterConcept: 52.86% probability\n",
      "- Find: 40.91% probability\n",
      "- QFilterStr: 2.99% probability\n",
      "\n",
      "Likely transitions from QueryRelation:\n",
      "\n",
      "Likely transitions from QueryAttrQualifier:\n",
      "\n",
      "Likely transitions from SelectBetween:\n",
      "\n",
      "Likely transitions from Count:\n",
      "\n",
      "Likely transitions from QueryRelationQualifier:\n",
      "\n",
      "Likely transitions from VerifyDate:\n",
      "\n",
      "Likely transitions from VerifyYear:\n",
      "\n",
      "Likely transitions from Or:\n",
      "- Count: 100.00% probability\n",
      "\n",
      "Likely transitions from QFilterStr:\n",
      "- FilterConcept: 100.00% probability\n",
      "\n",
      "Likely transitions from FilterYear:\n",
      "- FilterConcept: 85.57% probability\n",
      "- Find: 5.19% probability\n",
      "- Relate: 3.09% probability\n",
      "\n",
      "Likely transitions from QFilterNum:\n",
      "- FilterConcept: 100.00% probability\n",
      "\n",
      "Likely transitions from VerifyNum:\n",
      "\n",
      "Likely transitions from FilterDate:\n",
      "- Find: 38.11% probability\n",
      "- FilterConcept: 23.54% probability\n",
      "- Relate: 13.12% probability\n",
      "\n",
      "Likely transitions from QueryAttrUnderCondition:\n",
      "- VerifyNum: 52.16% probability\n",
      "- VerifyYear: 38.69% probability\n",
      "- VerifyStr: 7.54% probability\n",
      "\n",
      "Likely transitions from QFilterDate:\n",
      "- FilterConcept: 100.00% probability\n",
      "\n",
      "Likely transitions from QFilterYear:\n",
      "- FilterConcept: 100.00% probability\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "from collections import defaultdict\n",
    "import json \n",
    "\n",
    "# ... existing analysis code ...\n",
    "\n",
    "class FunctionStateMachine:\n",
    "    \"\"\"\n",
    "    Finite State Machine for function call transitions based on bigram analysis\n",
    "    \n",
    "    Attributes:\n",
    "        transitions: Dict[current_function, Dict[next_function, count]]\n",
    "        start_states: Counter for initial functions\n",
    "        end_states: Counter for terminal functions\n",
    "    \n",
    "    Example:\n",
    "        >>> fsm = FunctionStateMachine.from_bigrams(analysis['common_bigrams'])\n",
    "        >>> fsm.get_likely_transitions('query_data')\n",
    "        [('preprocess', 0.6), ('validate', 0.4)]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, transitions: Dict[str, Dict[str, int]]):\n",
    "        self.transitions = transitions\n",
    "        self.start_states = Counter()\n",
    "        self.end_states = Counter()\n",
    "        \n",
    "    @classmethod\n",
    "    def from_bigrams(cls, bigrams: List[Tuple[Tuple[str, str], int]]):\n",
    "        \"\"\"Build state machine from bigram analysis results\"\"\"\n",
    "        transitions = defaultdict(lambda: defaultdict(int))\n",
    "        start_functions = Counter()\n",
    "        end_functions = Counter()\n",
    "        \n",
    "        for (f1, f2), count in bigrams:\n",
    "            transitions[f1][f2] += count\n",
    "            start_functions[f1] += count\n",
    "            end_functions[f2] += count\n",
    "            \n",
    "        # Normalize start/end probabilities\n",
    "        total = sum(start_functions.values())\n",
    "        cls.start_states = {k: v/total for k, v in start_functions.items()}\n",
    "        cls.end_states = {k: v/total for k, v in end_functions.items()}\n",
    "        \n",
    "        return cls(transitions)\n",
    "    \n",
    "    def get_transition_prob(self, current: str, next_: str) -> float:\n",
    "        \"\"\"Get probability of transitioning to next function\"\"\"\n",
    "        total = sum(self.transitions[current].values())\n",
    "        return self.transitions[current].get(next_, 0) / total if total else 0\n",
    "    \n",
    "    def get_likely_transitions(self, current: str, top_n: int = 3) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Get most probable next states with probabilities\"\"\"\n",
    "        transitions = self.transitions.get(current, {})\n",
    "        total = sum(transitions.values())\n",
    "        if total == 0:\n",
    "            return []\n",
    "            \n",
    "        sorted_trans = sorted(\n",
    "            transitions.items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )[:top_n]\n",
    "        \n",
    "        return [(func, count/total) for func, count in sorted_trans]\n",
    "    \n",
    "    def generate_validation_rules(self, min_support: int = 5) -> Dict[str, List[str]]:\n",
    "        \"\"\"Generate validation rules from frequent transitions\"\"\"\n",
    "        return {\n",
    "            func: list(transitions.keys())\n",
    "            for func, transitions in self.transitions.items()\n",
    "            if sum(transitions.values()) >= min_support\n",
    "        }\n",
    "    \n",
    "    def save_machine(self, path: str):\n",
    "        \"\"\"Save state machine to JSON file\"\"\"\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump({\n",
    "                'transitions': self.transitions,\n",
    "                'start_states': self.start_states,\n",
    "                'end_states': self.end_states\n",
    "            }, f)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_machine(cls, path: str):\n",
    "        \"\"\"Load state machine from JSON file\"\"\"\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "        return cls(\n",
    "            transitions=data['transitions'],\n",
    "            start_states=data['start_states'],\n",
    "            end_states=data['end_states']\n",
    "        )\n",
    "\n",
    "# Usage example\n",
    "fsm = FunctionStateMachine.from_bigrams(bigram_counter.items())\n",
    "\n",
    "# Generate validation rules\n",
    "validation_rules = fsm.generate_validation_rules(min_support=1)\n",
    "print(\"Validation Rules:\")\n",
    "for func, allowed in validation_rules.items():\n",
    "    print(f\"After {func}, allowed: {allowed}\")\n",
    "\n",
    "# Query example\n",
    "# current_function = \"FilterStr\"\n",
    "for current_function in function_freq.keys():   \n",
    "    print(f\"\\nLikely transitions from {current_function}:\")\n",
    "    for func, prob in fsm.get_likely_transitions(current_function):\n",
    "        print(f\"- {func}: {prob:.2%} probability\")\n",
    "\n",
    "# Save for later use\n",
    "fsm.save_machine(\"function_state_machine.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转移规则的 prompt 接口\n",
    "\n",
    "用于 api 方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Flexible Prompt ===\n",
      "After `FindAll`, consider these common next steps (probability shown):\n",
      "- `FilterStr` (69% likely)\n",
      "- `FilterNum` (16% likely)\n",
      "- `FilterYear` (12% likely)\n",
      "- `FilterDate` (3% likely)\n",
      "- `FilterConcept` (0% likely)\n",
      "Choose the most appropriate function or propose a valid alternative.\n",
      "\n",
      "=== Strict Prompt ===\n",
      "After calling `FindAll`, you MUST choose from these functions: `FilterStr`, `FilterNum`, `FilterYear`, `FilterDate`, `FilterConcept`. Provide your next step.\n",
      "\n",
      "=== System Prompt ===\n",
      "You are a workflow automation assistant. Follow these rules:\n",
      "    1. Maintain valid function call sequences\n",
      "    2. Prefer common patterns unless instructed otherwise\n",
      "    3. Explain your reasoning for non-standard choices\n",
      "\n",
      "    Current function call constraints:\n",
      "- After FindAll: FilterStr, FilterNum, FilterYear\n",
      "\n",
      "Response format: Markdown code block with function calls.\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "class FunctionPromptGenerator:\n",
    "    \"\"\"\n",
    "    Generate natural language prompts based on function transition rules\n",
    "    \n",
    "    Attributes:\n",
    "        fsm: FunctionStateMachine instance\n",
    "        templates: Dictionary of prompt templates\n",
    "        \n",
    "    Example:\n",
    "        >>> prompt_gen = FunctionPromptGenerator(fsm)\n",
    "        >>> print(prompt_gen.generate_prompt(\"query_data\"))\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fsm: FunctionStateMachine):\n",
    "        self.fsm = fsm\n",
    "        self.templates = {\n",
    "            'strict': (\n",
    "                \"After calling `{current_func}`, you MUST choose from these functions: \"\n",
    "                \"{allowed_funcs}. Provide your next step.\"\n",
    "            ),\n",
    "            'flexible': (\n",
    "                \"After `{current_func}`, consider these common next steps (probability shown):\\n\"\n",
    "                \"{func_list}\\n\"\n",
    "                \"Choose the most appropriate function or propose a valid alternative.\"\n",
    "            ),\n",
    "            'creative': (\n",
    "                \"Your last step was `{current_func}`. While these are common next steps:\\n\"\n",
    "                \"{func_list}\\n\"\n",
    "                \"You may also propose innovative sequences that maintain logical coherence.\"\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def generate_prompt(\n",
    "        self,\n",
    "        current_func: str,\n",
    "        mode: str = 'flexible',\n",
    "        max_suggestions: int = 5,\n",
    "        include_prob: bool = True\n",
    "    ) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Generate prompt based on current function state\n",
    "        \n",
    "        Args:\n",
    "            current_func: Current function name\n",
    "            mode: Prompt strictness level (strict/flexible/creative)\n",
    "            max_suggestions: Maximum number of transitions to show\n",
    "            include_prob: Whether to include probability values\n",
    "            \n",
    "        Returns:\n",
    "            Formatted prompt string or None if no transitions\n",
    "        \"\"\"\n",
    "        transitions = self.fsm.get_likely_transitions(current_func, top_n=max_suggestions)\n",
    "        if not transitions:\n",
    "            return None\n",
    "            \n",
    "        # Format function list\n",
    "        func_list = []\n",
    "        for func, prob in transitions:\n",
    "            prob_desc = f\"({prob:.0%} likely)\" if include_prob else \"\"\n",
    "            func_list.append(f\"- `{func}` {prob_desc}\")\n",
    "        \n",
    "        return self.templates[mode].format(\n",
    "            current_func=current_func,\n",
    "            allowed_funcs=', '.join(f\"`{f[0]}`\" for f in transitions),\n",
    "            func_list='\\n'.join(func_list)\n",
    "        )\n",
    "    def format_as_system_prompt(self, history: List[str] = None) -> str:\n",
    "        \"\"\"Generate full system-level instruction prompt\"\"\"\n",
    "        base = \"\"\"You are a workflow automation assistant. Follow these rules:\n",
    "    1. Maintain valid function call sequences\n",
    "    2. Prefer common patterns unless instructed otherwise\n",
    "    3. Explain your reasoning for non-standard choices\n",
    "\n",
    "    Current function call constraints:\"\"\"\n",
    "        \n",
    "        if history:\n",
    "            current = history[-1]\n",
    "            transitions = self.fsm.get_likely_transitions(current)\n",
    "            rules = '\\n'.join([f\"- After {current}: {', '.join([f[0] for f in transitions])}\"])\n",
    "        else:\n",
    "            start_funcs = [f for f, _ in self.fsm.start_states.most_common(3)]\n",
    "            rules = f\"Start with: {', '.join(start_funcs)}\"\n",
    "        \n",
    "        return f\"{base}\\n{rules}\\n\\nResponse format: Markdown code block with function calls.\"\n",
    "\n",
    "\n",
    "\n",
    "# Usage example\n",
    "prompter = FunctionPromptGenerator(fsm)\n",
    "\n",
    "# Single step prompt\n",
    "current_function = \"FindAll\"\n",
    "print(\"=== Flexible Prompt ===\")\n",
    "print(prompter.generate_prompt(current_function))\n",
    "\n",
    "print(\"\\n=== Strict Prompt ===\")\n",
    "print(prompter.generate_prompt(current_function, mode='strict', include_prob=False))\n",
    "\n",
    "# 使用示例\n",
    "print(\"\\n=== System Prompt ===\")\n",
    "print(prompter.format_as_system_prompt([\"FindAll\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
